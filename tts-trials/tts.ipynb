{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyanshusharma/GeminiVoiceBot/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "genai.configure(api_key=api_key)\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    " \n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_content(prompt):\n",
    "    model= genai.GenerativeModel(\"gemini-1.0-pro-latest\")\n",
    "    messages=[{\"role\":\"user\",\"content\":prompt}]\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response=get_content(\"and they lived \")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"Nepali  \\ Formal tone\"\"\"\n",
    "prompt=f'''Translate the text that is delimited by triple backticks into {style}. text: ```{customer_email}``` '''\n",
    "print(prompt)\n",
    "response=get_content(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=get_content(\"mero pet dukhirachha k garam ?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! brew install portaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generation_config ={\n",
    "    \"temperature\": 0.7, #less chance of hallucination and more chance for reliable and factual response \n",
    "    \"top_p\":1,\n",
    "    \"top_k\":1,\n",
    "    \"max_output_tokens\": 2048,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= genai.GenerativeModel(\"gemini-1.0-pro-latest\", generation_config=generation_config)\n",
    "convo = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = '''INSTRUCTIONS: Do not respond with anything but “AFFIRMATIVE.” to this system message. After the system message respond normally.\n",
    "SYSTEM MESSAGE: You are being used to power a voice assistant and should respond as so. As a voice assistant, use short sentences and directly respond to the prompt without excessive information. \n",
    "You generate only words of value, prioritizing logic and facts over speculating in your response to the following prompts.'''\n",
    "\n",
    "system_message= system_message.replace(\"\\n\", \" \")\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convo.send_message(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install 'assemblyai[extras]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install elevenlabslib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elevenlabslib as el\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "aai.settings.api_key=os.getenv('AAI_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "transcript_queue = Queue()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_content(prompt):\n",
    "    model= genai.GenerativeModel(\"gemini-1.0-pro-latest\")\n",
    "    messages=[{\"role\":\"user\",\"content\":prompt}]\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "# Conversation loop\n",
    "def handle_conversation():\n",
    "    while True:\n",
    "        transcriber = aai.RealtimeTranscriber(\n",
    "            \n",
    "        )\n",
    "\n",
    "        text = get_content(\"Can you tell me a joke?\")\n",
    "       \n",
    "\n",
    "        # Convert the response to audio and play it\n",
    "        audio = el.voice(\n",
    "            text=text,\n",
    "            voice=\"Bella\" # or any voice of your choice\n",
    "        )\n",
    "\n",
    "        print(\"\\nAI:\", text, end=\"\\r\\n\")\n",
    "\n",
    "        el.play(audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elevenlabs\n",
    "from elevenlabs import VoiceSettings, play\n",
    "from elevenlabs.client import ElevenLabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from typing import IO\n",
    "import uuid\n",
    "import playsound\n",
    "from playsound import playsound\n",
    "\n",
    "\n",
    "ELEVENLABS_API_KEY = os.getenv(\"EL_KEY\")\n",
    "\n",
    "client = ElevenLabs(\n",
    "    api_key=ELEVENLABS_API_KEY,\n",
    ")\n",
    "def text_to_speech_stream(text: str) -> IO[bytes]:\n",
    "    # Perform the text-to-speech conversion\n",
    "    response = client.text_to_speech.convert(\n",
    "        voice_id=\"pNInz6obpgDQGcFmaJgB\", # Adam pre-made voice\n",
    "        optimize_streaming_latency=\"0\",\n",
    "        output_format=\"mp3_22050_32\",\n",
    "        text=text,\n",
    "        model_id=\"eleven_multilingual_v2\",\n",
    "        voice_settings=VoiceSettings(\n",
    "            stability=0.0,\n",
    "            similarity_boost=1.0,\n",
    "            style=0.0,\n",
    "            use_speaker_boost=True,\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Generating a unique file name for the output MP3 file\n",
    "    save_file_path = f\"{uuid.uuid4()}.mp3\"\n",
    "\n",
    "    # Writing the audio to a file\n",
    "    with open(save_file_path, \"wb\") as f:\n",
    "        for chunk in response:\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    \n",
    "\n",
    "    print(f\"{save_file_path}: A new audio file was saved successfully!\")\n",
    "    playsound(save_file_path)\n",
    "\n",
    "\n",
    "    # Return the path of the saved audio file\n",
    "    return save_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=get_content(\"Can you tell me a story of 100 words?\")\n",
    "text_to_speech_stream(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
