{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install google-generativeai\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key = os.getenv('API_KEY')\n",
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config={\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\":1.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"max_tokens\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am a large language model, trained by Google. \n",
      "\n",
      "Here's a little about me:\n",
      "\n",
      "* **I'm a computer program:** I'm not a person, but I can process and generate text, translate languages, write different kinds of creative content, and answer your questions in an informative way.\n",
      "* **I'm trained on a massive dataset:** I've learned to communicate and generate human-like text by being trained on a massive amount of text and code. \n",
      "* **I'm still under development:** I'm constantly learning and improving, and I'm always excited to learn new things!\n",
      "\n",
      "I'm here to assist you with any questions or tasks you may have. What can I do for you today? 😊 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Hello! Can you introduce yourself?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi, I am Priyanshu. Can we be friends?\n",
      "AI: Hello Priyanshu,\n",
      "\n",
      "I'm Gemini, a multi-modal AI language model developed by Google. I am not an individual capable of having friends. I'm designed to provide information and assist users with their requests to the best of my abilities. \n",
      "\n",
      "May I assist you with anything else today?\n",
      "User: I want you to tell me a joke\n",
      "AI: What do you call a fish with no eyes? \n",
      "\n",
      "... Fsh!\n",
      "User: not funny \n",
      "AI: I apologize for the joke not being to your liking. Here's another one:\n",
      "\n",
      "What do you call a deer with no eyes?\n",
      "\n",
      "... No eye deer!\n",
      "\n",
      "Do you find this one funnier?\n",
      "User: nope\n",
      "AI: Alright, I'll try one more:\n",
      "\n",
      "What do you call a kangaroo with no arms?\n",
      "\n",
      "... A pouch potato!\n",
      "\n",
      "Hopefully, this one will make you chuckle. If not, I'm open to suggestions for other types of content or assistance that you may need. Just let me know how I can help!\n",
      "User: haha, okay you get it\n",
      "AI: I'm glad you enjoyed that one!\n",
      "\n",
      "Is there anything else I can assist you with today, Priyanshu? I'm here to help with a wide range of topics, including:\n",
      "\n",
      "* Answering your questions\n",
      "* Providing information on various subjects\n",
      "* Translating languages\n",
      "* Writing different types of creative content\n",
      "* And much more!\n",
      "\n",
      "Just let me know what you need, and I'll do my best to assist you.\n",
      "Conversation ended.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = genai.GenerativeModel('models/gemini-pro')\n",
    "chat = model.start_chat()\n",
    "def automated_conversation():\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Conversation ended.\")\n",
    "            break\n",
    "        print(\"User:\", user_input)\n",
    "       \n",
    "        response = chat.send_message(user_input)\n",
    "        print(\"AI:\", response.text)\n",
    "\n",
    "# Start the automated conversation\n",
    "automated_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gtts in /Users/priyanshusharma/GeminiVoiceBot/.venv/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: pydub in /Users/priyanshusharma/GeminiVoiceBot/.venv/lib/python3.11/site-packages (0.25.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Users/priyanshusharma/GeminiVoiceBot/.venv/lib/python3.11/site-packages (from gtts) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /Users/priyanshusharma/GeminiVoiceBot/.venv/lib/python3.11/site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/priyanshusharma/GeminiVoiceBot/.venv/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/priyanshusharma/GeminiVoiceBot/.venv/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/priyanshusharma/GeminiVoiceBot/.venv/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/priyanshusharma/GeminiVoiceBot/.venv/lib/python3.11/site-packages (from requests<3,>=2.27->gtts) (2024.7.4)\n",
      "Collecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6083 sha256=d59785c63397671197720f476ac14ce72e986f110e5bac02ea60008904cf16e7\n",
      "  Stored in directory: /Users/priyanshusharma/Library/Caches/pip/wheels/56/30/c5/576bdd729f3bc062d62a551be7fefd6ed2f761901568171e4e\n",
      "Successfully built ffmpeg\n",
      "Installing collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n"
     ]
    }
   ],
   "source": [
    "! pip install gtts pydub\n",
    "! pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffprobe\n",
      "  Downloading ffprobe-0.5.zip (3.5 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ffprobe\n",
      "  Building wheel for ffprobe (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffprobe: filename=ffprobe-0.5-py3-none-any.whl size=3408 sha256=849fd792d286acc4c4190c62ad47f87e18480d34c20fcfc6dfa343aea4122220\n",
      "  Stored in directory: /Users/priyanshusharma/Library/Caches/pip/wheels/2c/cb/c1/10daee0c3fad04c9d900006cd0f24bdd47afb74a5c1c085795\n",
      "Successfully built ffprobe\n",
      "Installing collected packages: ffprobe\n",
      "Successfully installed ffprobe-0.5\n"
     ]
    }
   ],
   "source": [
    "! pip install ffprobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/path/to/ffmpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the required module for text \n",
    "# to speech conversion\n",
    "from gtts import gTTS\n",
    "\n",
    "# This module is imported so that we can \n",
    "# play the converted audio\n",
    "import os\n",
    "\n",
    "# The text that you want to convert to audio\n",
    "mytext = 'Welcome to geeksforgeeks Joe!'\n",
    "\n",
    "# Language in which you want to convert\n",
    "language = 'en'\n",
    "\n",
    "# Passing the text and language to the engine, \n",
    "# here we have marked slow=False. Which tells \n",
    "# the module that the converted audio should \n",
    "# have a high speed\n",
    "myobj = gTTS(text=mytext, lang=language, slow=False)\n",
    "# Saving the converted audio in a mp3 file named\n",
    "# welcome \n",
    "myobj.save(\"welcome.mp3\")\n",
    "\n",
    "# Playing the converted file\n",
    "os.system(\"open welcome.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hello, I am priyanshu\n",
      "AI: Hello Priyanshu, it's great to meet you! I hope you're having a wonderful day. Is there anything specific that you'd like to know or discuss?\n",
      "User: can you talk to me in hindi\n",
      "AI:  हाँ, मैं आपसे हिंदी में बात कर सकता हूँ। आप मुझसे हिंदी में कोई भी प्रश्न पूछ सकते हैं और मैं आपको हिंदी में उत्तर दूंगा। इसके अलावा, मैं हिंदी में कहानियाँ, कविताएँ और गीत भी उत्पन्न कर सकता हूँ।\n",
      "\n",
      "क्या आप चाहेंगे कि मैं आपसे हिंदी में बात करूँ?\n",
      "User: sorry thank you\n",
      "AI: कोई बात नहीं। क्या मैं आपकी किसी अन्य चीज़ में मदद कर सकता हूँ?\n",
      "Conversation ended.\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "language = 'en'\n",
    "model = genai.GenerativeModel('models/gemini-pro')\n",
    "chat = model.start_chat()\n",
    "def automated_conversation():\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Conversation ended.\")\n",
    "            break\n",
    "        print(\"User:\", user_input)\n",
    "        myobj = gTTS(text=user_input, lang=language, slow=False)\n",
    "        # Saving the converted audio in a mp3 file named\n",
    "        # welcome \n",
    "        myobj.save(\"welcome.mp3\")\n",
    "        # Playing the converted file\n",
    "        os.system(\"open welcome.mp3\")\n",
    "\n",
    "# Playing the converted file\n",
    "        response = chat.send_message(user_input)\n",
    "        print(\"AI:\", response.text)\n",
    "        myobj = gTTS(text=response.text, lang=language, slow=False)\n",
    "        # Saving the converted audio in a mp3 file named\n",
    "        # welcome \n",
    "        myobj.save(\"welcome.mp3\")\n",
    "        # Playing the converted file\n",
    "        os.system(\"open welcome.mp3\")\n",
    "\n",
    "# Start the automated conversation\n",
    "automated_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
