{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install google-generativeai\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyanshusharma/GeminiVoiceBot/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAI_API_KEY = os.getenv('API_KEY')\n",
    "genai.configure(api_key=GAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config={\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\":1.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"max_tokens\": 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namaste! üôè  \n",
      "\n",
      "It's great to hear you're doing well!  \"Ali sancho vayena\" means \"Are you well?\"  \n",
      "\n",
      "How can I help you today? üòä \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\"Namaste Doctor! ali sancho vayena\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('models/gemini-pro')\n",
    "chat = model.start_chat()\n",
    "\n",
    "# Send messages and print responses\n",
    "response = chat.send_message(input(\"Enter your message: \"))\n",
    "print(response.text)  # Print the first response\n",
    "\n",
    "response = chat.send_message(input(\"Enter your message: \"))\n",
    "print(response.text)  # Print the second response\n",
    "\n",
    "\n",
    "\n",
    "# Continue the conversation\n",
    "response = chat.send_message(input(\"Enter your message: \"))\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: when is christmas?\n",
      "AI: December 25th\n",
      "User: are you sure?\n",
      "AI: Yes, I am sure that Christmas is on December 25th. Christmas is celebrated on December 25th in most countries around the world, including the United States, the United Kingdom, Canada, Australia, and many others.\n",
      "User: do you know what question I asked you\n",
      "AI: Yes, the question you asked me was \"are you sure?\".\n",
      "\n",
      "I understand that you may be trying to trick me by asking me a question that I have already answered, but I am confident in my answer. Christmas is on December 25th.\n",
      "User: haha nice one, you are funny \n",
      "AI: Thank you, I'm glad you think so. I try my best to be helpful and informative, but I also enjoy having a little fun along the way.\n",
      "\n",
      "Is there anything else I can help you with today?\n",
      "User: what was the first question i asked you today\n",
      "AI: The first question you asked me today was \"when is christmas?\".\n",
      "\n",
      "I hope this helps! Let me know if you have any other questions.\n",
      "User: do you remember\n",
      "AI: Yes, I remember that the first question you asked me today was \"when is christmas?\".\n",
      "\n",
      "I have a very good memory, and I am able to recall information that I have learned in the past. This allows me to answer your questions accurately and efficiently.\n",
      "\n",
      "Is there anything else I can help you with today?\n",
      "User: thanks boy\n",
      "AI: You're welcome! I'm glad I could be of assistance.\n",
      "\n",
      "Please let me know if you have any other questions. I'm here to help.\n",
      "Conversation ended.\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel('models/gemini-pro')\n",
    "chat = model.start_chat()\n",
    "def automated_conversation():\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Conversation ended.\")\n",
    "            break\n",
    "        print(\"User:\", user_input)\n",
    "        response = chat.send_message(user_input)\n",
    "        print(\"AI:\", response.text)\n",
    "\n",
    "# Start the automated conversation\n",
    "automated_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
