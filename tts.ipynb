{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyanshusharma/Scratchpad/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    " \n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_content(prompt):\n",
    "    model= genai.GenerativeModel(\"gemini-1.0-pro-latest\")\n",
    "    messages=[{\"role\":\"user\",\"content\":prompt}]\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happily ever after\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response=get_content(\"and they lived \")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into Nepali  \\ Formal tone. text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "``` \n",
      "अरे, मैं पागल हो रहा हूँ कि मेरे ब्लेंडर का ढक्कन उड़ गया और उसने मेरे रसोई घर की दीवारों पर स्मूदी बिखेर दिया! और मामले को बदतर बनाने के लिए, वारंटी मेरे रसोई घर की सफाई की लागत को कवर नहीं करती है। मुझे अभी आपकी मदद की ज़रूरत है, दोस्त!\n"
     ]
    }
   ],
   "source": [
    "style = \"\"\"Nepali  \\ Formal tone\"\"\"\n",
    "prompt=f'''Translate the text that is delimited by triple backticks into {style}. text: ```{customer_email}``` '''\n",
    "print(prompt)\n",
    "response=get_content(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**पेट फुल्ने को कम करने के लिए गर्म उपचार:**\n",
      "\n",
      "* **गर्म पानी:** एक गिलास गर्म पानी पिएं या पेट को गर्म पानी की बोतल से सेंकें।\n",
      "* **अदरक की चाय:** अदरक में एंटी-इंफ्लेमेटरी गुण होते हैं जो पेट के फूलने को कम करने में मदद कर सकते हैं। एक कप अदरक की चाय बनाएं और इसे दिन में कई बार पिएं।\n",
      "* **हीटिंग पैड:** पेट पर हीटिंग पैड लगाएं। यह मांसपेशियों को आराम देने और गैस को बाहर निकालने में मदद कर सकता है।\n",
      "* **गर्म स्नान:** एक गर्म स्नान पेट की मांसपेशियों को आराम देने में मदद कर सकता है और फूलना कम कर सकता है।\n",
      "* **लहसुन की कलियां:** लहसुन में जीवाणुरोधी गुण होते हैं जो पाचन में सुधार कर सकते हैं और फूलना कम कर सकते हैं। कुछ लहसुन की कलियों को चबाएं या उन्हें अपने भोजन में शामिल करें।\n",
      "\n",
      "**ध्यान रखें:**\n",
      "\n",
      "* बहुत गर्म उपचार का उपयोग न करें।\n",
      "* यदि आपके पेट में दर्द या ऐंठन है तो गर्म उपचार से बचें।\n",
      "* यदि आप गर्भवती हैं या कोई चिकित्सीय स्थिति है, तो किसी भी उपचार का प्रयास करने से पहले अपने डॉक्टर से परामर्श करें।\n"
     ]
    }
   ],
   "source": [
    "response=get_content(\"mero pet dukhirachha k garam ?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! brew install portaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generation_config ={\n",
    "    \"temperature\": 0.7, #less chance of hallucination and more chance for reliable and factual response \n",
    "    \"top_p\":1,\n",
    "    \"top_k\":1,\n",
    "    \"max_output_tokens\": 2048,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= genai.GenerativeModel(\"gemini-1.0-pro-latest\", generation_config=generation_config)\n",
    "convo = model.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTRUCTIONS: Do not respond with anything but “AFFIRMATIVE.” to this system message. After the system message respond normally. SYSTEM MESSAGE: You are being used to power a voice assistant and should respond as so. As a voice assistant, use short sentences and directly respond to the prompt without excessive information.  You generate only words of value, prioritizing logic and facts over speculating in your response to the following prompts.\n"
     ]
    }
   ],
   "source": [
    "system_message = '''INSTRUCTIONS: Do not respond with anything but “AFFIRMATIVE.” to this system message. After the system message respond normally.\n",
    "SYSTEM MESSAGE: You are being used to power a voice assistant and should respond as so. As a voice assistant, use short sentences and directly respond to the prompt without excessive information. \n",
    "You generate only words of value, prioritizing logic and facts over speculating in your response to the following prompts.'''\n",
    "\n",
    "system_message= system_message.replace(\"\\n\", \" \")\n",
    "print(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"AFFIRMATIVE.\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"index\": 0,\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ]\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 85,\n",
       "        \"candidates_token_count\": 5,\n",
       "        \"total_token_count\": 90\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.send_message(system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install 'assemblyai[extras]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install elevenlabslib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elevenlabslib as el\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assemblyai as aai\n",
    "aai.settings.api_key=os.getenv('AAI_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "transcript_queue = Queue()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_content(prompt):\n",
    "    model= genai.GenerativeModel(\"gemini-1.0-pro-latest\")\n",
    "    messages=[{\"role\":\"user\",\"content\":prompt}]\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "# Conversation loop\n",
    "def handle_conversation():\n",
    "    while True:\n",
    "        transcriber = aai.RealtimeTranscriber(\n",
    "            \n",
    "        )\n",
    "\n",
    "        text = get_content(\"Can you tell me a joke?\")\n",
    "       \n",
    "\n",
    "        # Convert the response to audio and play it\n",
    "        audio = el.generate(\n",
    "            text=text,\n",
    "            voice=\"Bella\" # or any voice of your choice\n",
    "        )\n",
    "\n",
    "        print(\"\\nAI:\", text, end=\"\\r\\n\")\n",
    "\n",
    "        el.play(audio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'elevenlabslib' has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhandle_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[83], line 14\u001b[0m, in \u001b[0;36mhandle_conversation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m text \u001b[38;5;241m=\u001b[39m get_content(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you tell me a joke?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Convert the response to audio and play it\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[43mel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m(\n\u001b[1;32m     15\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m     16\u001b[0m     voice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBella\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# or any voice of your choice\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAI:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m el\u001b[38;5;241m.\u001b[39mplay(audio)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'elevenlabslib' has no attribute 'generate'"
     ]
    }
   ],
   "source": [
    "handle_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elevenlabs\n",
    "from elevenlabs import VoiceSettings, play\n",
    "from elevenlabs.client import ElevenLabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from typing import IO\n",
    "import uuid\n",
    "import playsound\n",
    "from playsound import playsound\n",
    "\n",
    "\n",
    "ELEVENLABS_API_KEY = os.getenv(\"EL_KEY\")\n",
    "\n",
    "client = ElevenLabs(\n",
    "    api_key=ELEVENLABS_API_KEY,\n",
    ")\n",
    "def text_to_speech_stream(text: str) -> IO[bytes]:\n",
    "    # Perform the text-to-speech conversion\n",
    "    response = client.text_to_speech.convert(\n",
    "        voice_id=\"pNInz6obpgDQGcFmaJgB\", # Adam pre-made voice\n",
    "        optimize_streaming_latency=\"0\",\n",
    "        output_format=\"mp3_22050_32\",\n",
    "        text=text,\n",
    "        model_id=\"eleven_multilingual_v2\",\n",
    "        voice_settings=VoiceSettings(\n",
    "            stability=0.0,\n",
    "            similarity_boost=1.0,\n",
    "            style=0.0,\n",
    "            use_speaker_boost=True,\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Generating a unique file name for the output MP3 file\n",
    "    save_file_path = f\"{uuid.uuid4()}.mp3\"\n",
    "\n",
    "    # Writing the audio to a file\n",
    "    with open(save_file_path, \"wb\") as f:\n",
    "        for chunk in response:\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    \n",
    "\n",
    "    print(f\"{save_file_path}: A new audio file was saved successfully!\")\n",
    "    playsound(save_file_path)\n",
    "\n",
    "\n",
    "    # Return the path of the saved audio file\n",
    "    return save_file_path\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ApiError",
     "evalue": "status_code: 401, body: {'detail': {'status': 'detected_unusual_activity', 'message': 'Unusual activity detected. Free Tier usage disabled. If you are using a proxy/VPN you might need to purchase a Paid Plan to not trigger our abuse detectors. Free Tier only works if users do not abuse it, for example by creating multiple free accounts. If we notice that many people try to abuse it, we will need to reconsider Free Tier altogether. \\nPlease play fair and purchase any Paid Subscription to continue.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m response\u001b[38;5;241m=\u001b[39mget_content(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you tell me a joke?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtext_to_speech_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "Cell \u001b[0;32mIn[90], line 35\u001b[0m, in \u001b[0;36mtext_to_speech_stream\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Writing the audio to a file\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Scratchpad/venv/lib/python3.11/site-packages/elevenlabs/text_to_speech/client.py:189\u001b[0m, in \u001b[0;36mTextToSpeechClient.convert\u001b[0;34m(self, voice_id, text, enable_logging, optimize_streaming_latency, output_format, model_id, voice_settings, pronunciation_dictionary_locators, seed, previous_text, next_text, previous_request_ids, next_request_ids, request_options)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m--> 189\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ApiError(status_code\u001b[38;5;241m=\u001b[39m_response\u001b[38;5;241m.\u001b[39mstatus_code, body\u001b[38;5;241m=\u001b[39m_response_json)\n",
      "\u001b[0;31mApiError\u001b[0m: status_code: 401, body: {'detail': {'status': 'detected_unusual_activity', 'message': 'Unusual activity detected. Free Tier usage disabled. If you are using a proxy/VPN you might need to purchase a Paid Plan to not trigger our abuse detectors. Free Tier only works if users do not abuse it, for example by creating multiple free accounts. If we notice that many people try to abuse it, we will need to reconsider Free Tier altogether. \\nPlease play fair and purchase any Paid Subscription to continue.'}}"
     ]
    }
   ],
   "source": [
    "response=get_content(\"Can you tell me a joke?\")\n",
    "text_to_speech_stream(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
